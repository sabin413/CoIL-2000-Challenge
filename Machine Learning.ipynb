{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Potential Customers For an Insurance Policy - CoIL 2000 Challenge - Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready for machine learning. We will start from logistic regression and then we will go to neural networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the feature description txt. file and make a list of feature names\n",
    "features_list = [] \n",
    "fh = open('TicDataDescr.txt', 'r')\n",
    "for i, line in enumerate(fh):\n",
    "    if 32 < i < 51: # 204:\n",
    "        features_list.append(line.rstrip('\\n')[2:])\n",
    "    elif 51 <= i< 204:\n",
    "        features_list.append(line.rstrip('\\n')[3:])\n",
    "fh.close()\n",
    "\n",
    "while '' in features_list:\n",
    "    features_list.remove('')\n",
    "#print(features_list)\n",
    "#len(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_table('ticdata2000.txt', names=features_list) # assign the feature names from the list prepared before\n",
    "#df_test = pd.read_table('ticeval2000.txt', names=features_list) # test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348 5.977327378907592\n"
     ]
    }
   ],
   "source": [
    "# Find the total number of positive class in the target - baseline\n",
    "ls = list(df['CARAVAN Number of mobile home policies 0 - 1'].values)\n",
    "num_policy_users = ls.count(1)\n",
    "num_nonusers = ls.count(0)\n",
    "users_perc = num_policy_users*100/(num_policy_users+num_nonusers)\n",
    "print(num_policy_users, users_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a baseline for our models here, 348 out of 5822 customers, which is about 6%, own the insurence policy. This means only 6% of the total customers belong to the positive class and hence the data is unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Modeling - Logistic Regression\n",
    "import numpy as np\n",
    "X = df.drop('CARAVAN Number of mobile home policies 0 - 1',axis = 1) #feature\n",
    "X['MOSTYPE Customer Subtype see L0']  = np.log(1+X['MOSTYPE Customer Subtype see L0'].values) # rescale this column\n",
    "y = df['CARAVAN Number of mobile home policies 0 - 1'] #target\n",
    "#X_testset = df_test.drop('CARAVAN Number of mobile home policies 0 - 1',axis = 1)\n",
    "#X_testset['MOSTYPE Customer Subtype see L0'] = np.log(1+X_testset['MOSTYPE Customer Subtype see L0'].values)\n",
    "#y_testset = df_test['CARAVAN Number of mobile home policies 0 - 1']\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "logreg = LogisticRegression() # instantiate the model\n",
    "logreg.fit(X_train,y_train) # fit the data\n",
    "y_pred = logreg.predict(X_test) \n",
    "#X['MOSTYPE Customer Subtype see L0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1356,    5],\n",
       "       [  93,    2]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model evaluation by confusion matrix\n",
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9326923076923077\n",
      "Precision: 0.2857142857142857\n",
      "Recall: 0.021052631578947368\n"
     ]
    }
   ],
   "source": [
    "# model evaluation by accuracy, precission and Recall\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is good, precision is low, and the recall is even lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = tp+tn/tp+tn + fp+fn (tn, fp, fn, tp)\n",
    "# precision = tp/tp+fp - if predicted to be positive, what is the prob that it is true?\n",
    "# recall = tp/tp+fn -  out of total positive cases, how many are predicted as positive? also known\n",
    "# as true positive rate. Look for true negative rate too.\n",
    "#a b// c, d sencitivity = d/c+d,  tp/tp+fn , specificity = a/a+b, tn/tn+fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Since it is an unbalanced data, we try Upsampling and Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4113\n",
      "1     253\n",
      "Name: CARAVAN Number of mobile home policies 0 - 1, dtype: int64\n",
      "[4113 4113]\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts()) # count the numbers of 0 and 1 before sampling\n",
    "smt = SMOTE()\n",
    "X_train1, y_train1 = smt.fit_sample(X_train, y_train)\n",
    "y_train.value_counts()\n",
    "print(np.bincount(y_train1)) # count the numbers of 0 and 1 after sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[995 366]\n",
      " [ 46  49]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1361\n",
       "1      95\n",
       "Name: CARAVAN Number of mobile home policies 0 - 1, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train1,y_train1) # fit the data\n",
    "y_pred = logreg.predict(X_test) \n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(cnf_matrix)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,15,'Predicted label')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the confusion matrix by using a heatmap\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.717032967032967\n",
      "Precision: 0.1180722891566265\n",
      "Recall: 0.5157894736842106\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is around 70% which is reasonable. To understand how good are the values of precision and recall, \n",
    "the precision of 0.12 means that if an observation is predicted to be positive, there is 12% chance that it is actually positive.\n",
    "Compared to our base value (which is 6% from a random guess), its a significant improvement. Similarly, the value of recall is 0.52\n",
    "meaning that out of all positve class cases 52% were identified as positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[450 911]\n",
      " [ 30  65]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Now, do down sampling applying NearMiss\n",
    "from imblearn.under_sampling import NearMiss\n",
    "nr = NearMiss()\n",
    "X_train2, y_train2 = nr.fit_sample(X_train, y_train)\n",
    "np.bincount(y_train2)\n",
    "\n",
    "logreg.fit(X_train2, y_train2) # fit the data\n",
    "y_pred = logreg.predict(X_test) \n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35370879120879123\n",
      "Precision: 0.06659836065573771\n",
      "Recall: 0.6842105263157895\n"
     ]
    }
   ],
   "source": [
    "# model evaluation by accuracy, precission and Recall\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better than before in recall but worse in accuracy and precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Neural network in Keras\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "n_cols = df.shape[1]-1\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "# create baseline model\n",
    "def create_baseline(optimizer='rmsprop', init = 'uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(85, activation='relu', input_dim=n_cols))\n",
    "    model.add(Dense(85, activation='relu'))\n",
    "    model.add(Dense(85, activation='relu'))\n",
    "    model.add(Dense(85, activation='relu'))\n",
    "    model.add(Dense(85, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabin\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.942052 using {'batch_size': 10, 'epochs': 60, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "total time: 960.1043825149536\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning by GridsearchCV\n",
    "start = time()\n",
    "model = KerasClassifier(build_fn=create_baseline, verbose = 0)\n",
    "\n",
    "inits = ['glorot_uniform', 'normal']\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "epochs = np.array([60])\n",
    "batches = np.array([10])\n",
    "\n",
    "param_dict = dict(optimizer=optimizers, epochs=epochs, batch_size=batches, init=inits)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_dict)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "#for params, mean_score, scores in grid_result.grid_scores_:\n",
    "#    print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))\n",
    "print(\"total time:\",time()-start)\n",
    "best_epochs = grid_result.best_params_['epochs']\n",
    "best_batch_size = grid_result.best_params_['batch_size']\n",
    "best_init = grid_result.best_params_['init']\n",
    "best_optimizer = grid_result.best_params_['optimizer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridsearchCV is very slow, so we tune the hyperparameters manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "4366/4366 [==============================] - 3s 744us/step - loss: 0.2209 - acc: 0.9418\n",
      "Epoch 2/60\n",
      "4366/4366 [==============================] - 2s 430us/step - loss: 0.2060 - acc: 0.9421\n",
      "Epoch 3/60\n",
      "4366/4366 [==============================] - 2s 426us/step - loss: 0.1987 - acc: 0.9421\n",
      "Epoch 4/60\n",
      "4366/4366 [==============================] - 2s 419us/step - loss: 0.1952 - acc: 0.9421\n",
      "Epoch 5/60\n",
      "4366/4366 [==============================] - 2s 423us/step - loss: 0.1933 - acc: 0.9421\n",
      "Epoch 6/60\n",
      "4366/4366 [==============================] - 2s 417us/step - loss: 0.1903 - acc: 0.9421\n",
      "Epoch 7/60\n",
      "4366/4366 [==============================] - 2s 420us/step - loss: 0.1832 - acc: 0.9421\n",
      "Epoch 8/60\n",
      "4366/4366 [==============================] - 2s 420us/step - loss: 0.1847 - acc: 0.9421\n",
      "Epoch 9/60\n",
      "4366/4366 [==============================] - 2s 429us/step - loss: 0.1780 - acc: 0.9423\n",
      "Epoch 10/60\n",
      "4366/4366 [==============================] - 2s 421us/step - loss: 0.1753 - acc: 0.9425\n",
      "Epoch 11/60\n",
      "4366/4366 [==============================] - 2s 400us/step - loss: 0.1698 - acc: 0.9423\n",
      "Epoch 12/60\n",
      "4366/4366 [==============================] - 1s 276us/step - loss: 0.1637 - acc: 0.9450\n",
      "Epoch 13/60\n",
      "4366/4366 [==============================] - 1s 270us/step - loss: 0.1590 - acc: 0.9448\n",
      "Epoch 14/60\n",
      "4366/4366 [==============================] - 1s 285us/step - loss: 0.1571 - acc: 0.9448\n",
      "Epoch 15/60\n",
      "4366/4366 [==============================] - 1s 267us/step - loss: 0.1516 - acc: 0.9455\n",
      "Epoch 16/60\n",
      "4366/4366 [==============================] - 1s 270us/step - loss: 0.1486 - acc: 0.9478\n",
      "Epoch 17/60\n",
      "4366/4366 [==============================] - 1s 269us/step - loss: 0.1459 - acc: 0.9492\n",
      "Epoch 18/60\n",
      "4366/4366 [==============================] - 1s 261us/step - loss: 0.1401 - acc: 0.9478\n",
      "Epoch 19/60\n",
      "4366/4366 [==============================] - 1s 275us/step - loss: 0.1383 - acc: 0.9482\n",
      "Epoch 20/60\n",
      "4366/4366 [==============================] - 1s 272us/step - loss: 0.1330 - acc: 0.9521\n",
      "Epoch 21/60\n",
      "4366/4366 [==============================] - 1s 254us/step - loss: 0.1287 - acc: 0.9487\n",
      "Epoch 22/60\n",
      "4366/4366 [==============================] - 1s 258us/step - loss: 0.1283 - acc: 0.9526\n",
      "Epoch 23/60\n",
      "4366/4366 [==============================] - 1s 275us/step - loss: 0.1258 - acc: 0.9505\n",
      "Epoch 24/60\n",
      "4366/4366 [==============================] - 1s 274us/step - loss: 0.1196 - acc: 0.9526\n",
      "Epoch 25/60\n",
      "4366/4366 [==============================] - 1s 268us/step - loss: 0.1181 - acc: 0.9551\n",
      "Epoch 26/60\n",
      "4366/4366 [==============================] - 1s 251us/step - loss: 0.1124 - acc: 0.9533\n",
      "Epoch 27/60\n",
      "4366/4366 [==============================] - 1s 268us/step - loss: 0.1137 - acc: 0.9553\n",
      "Epoch 28/60\n",
      "4366/4366 [==============================] - 1s 257us/step - loss: 0.1130 - acc: 0.9553\n",
      "Epoch 29/60\n",
      "4366/4366 [==============================] - 1s 270us/step - loss: 0.1051 - acc: 0.9595\n",
      "Epoch 30/60\n",
      "4366/4366 [==============================] - 1s 270us/step - loss: 0.1116 - acc: 0.9585\n",
      "Epoch 31/60\n",
      "4366/4366 [==============================] - 1s 263us/step - loss: 0.1010 - acc: 0.9634\n",
      "Epoch 32/60\n",
      "4366/4366 [==============================] - 1s 262us/step - loss: 0.1081 - acc: 0.9572\n",
      "Epoch 33/60\n",
      "4366/4366 [==============================] - 1s 278us/step - loss: 0.0951 - acc: 0.9604\n",
      "Epoch 34/60\n",
      "4366/4366 [==============================] - 1s 254us/step - loss: 0.0960 - acc: 0.9624\n",
      "Epoch 35/60\n",
      "4366/4366 [==============================] - 1s 277us/step - loss: 0.0897 - acc: 0.9643\n",
      "Epoch 36/60\n",
      "4366/4366 [==============================] - 1s 277us/step - loss: 0.0997 - acc: 0.9645\n",
      "Epoch 37/60\n",
      "4366/4366 [==============================] - 1s 258us/step - loss: 0.0847 - acc: 0.9654\n",
      "Epoch 38/60\n",
      "4366/4366 [==============================] - 1s 245us/step - loss: 0.0881 - acc: 0.9640\n",
      "Epoch 39/60\n",
      "4366/4366 [==============================] - 1s 247us/step - loss: 0.0836 - acc: 0.9691\n",
      "Epoch 40/60\n",
      "4366/4366 [==============================] - 1s 248us/step - loss: 0.0820 - acc: 0.9661\n",
      "Epoch 41/60\n",
      "4366/4366 [==============================] - 1s 261us/step - loss: 0.0867 - acc: 0.9663\n",
      "Epoch 42/60\n",
      "4366/4366 [==============================] - 1s 265us/step - loss: 0.0814 - acc: 0.9672\n",
      "Epoch 43/60\n",
      "4366/4366 [==============================] - 1s 265us/step - loss: 0.0760 - acc: 0.9670\n",
      "Epoch 44/60\n",
      "4366/4366 [==============================] - 1s 270us/step - loss: 0.0765 - acc: 0.9691\n",
      "Epoch 45/60\n",
      "4366/4366 [==============================] - 1s 268us/step - loss: 0.0761 - acc: 0.9698\n",
      "Epoch 46/60\n",
      "4366/4366 [==============================] - 1s 268us/step - loss: 0.0803 - acc: 0.9695\n",
      "Epoch 47/60\n",
      "4366/4366 [==============================] - 1s 260us/step - loss: 0.0751 - acc: 0.9718\n",
      "Epoch 48/60\n",
      "4366/4366 [==============================] - 1s 248us/step - loss: 0.0750 - acc: 0.9695\n",
      "Epoch 49/60\n",
      "4366/4366 [==============================] - 1s 270us/step - loss: 0.0752 - acc: 0.9721\n",
      "Epoch 50/60\n",
      "4366/4366 [==============================] - 1s 264us/step - loss: 0.0775 - acc: 0.9698\n",
      "Epoch 51/60\n",
      "4366/4366 [==============================] - 1s 244us/step - loss: 0.0700 - acc: 0.9709\n",
      "Epoch 52/60\n",
      "4366/4366 [==============================] - 1s 272us/step - loss: 0.0725 - acc: 0.9721\n",
      "Epoch 53/60\n",
      "4366/4366 [==============================] - 1s 270us/step - loss: 0.0627 - acc: 0.9737\n",
      "Epoch 54/60\n",
      "4366/4366 [==============================] - 1s 259us/step - loss: 0.0613 - acc: 0.9730\n",
      "Epoch 55/60\n",
      "4366/4366 [==============================] - 1s 268us/step - loss: 0.0828 - acc: 0.9682\n",
      "Epoch 56/60\n",
      "4366/4366 [==============================] - 1s 275us/step - loss: 0.0622 - acc: 0.9748\n",
      "Epoch 57/60\n",
      "4366/4366 [==============================] - 1s 276us/step - loss: 0.0620 - acc: 0.9737\n",
      "Epoch 58/60\n",
      "4366/4366 [==============================] - 1s 278us/step - loss: 0.0638 - acc: 0.9739\n",
      "Epoch 59/60\n",
      "4366/4366 [==============================] - 1s 280us/step - loss: 0.0594 - acc: 0.9771\n",
      "Epoch 60/60\n",
      "4366/4366 [==============================] - 1s 278us/step - loss: 0.0661 - acc: 0.9737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c0dc364e48>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do it manually\n",
    "best_epochs = 60\n",
    "best_batch_size = 10\n",
    "best_init = 'glorot_uniform'\n",
    "best_optimizer = 'adam'\n",
    "# Now create a classifier with manually chosen parameters\n",
    "classifier_pred = KerasClassifier(build_fn=create_baseline, optimizer=best_optimizer, init=best_init, epochs=best_epochs, batch_size=best_batch_size, verbose=1)\n",
    "classifier_pred.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1456/1456 [==============================] - 0s 135us/step\n",
      "[[1304   57]\n",
      " [  88    7]]\n",
      "Accuracy: 0.9004120879120879\n",
      "Precision: 0.109375\n",
      "Recall: 0.07368421052631578\n"
     ]
    }
   ],
   "source": [
    "y_pred=classifier_pred.predict(X_test)\n",
    "## calculate model performance\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression with upsampling is the best model so far. Now we try other classifiers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other classifiers\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classifiers = [GaussianNB(var_smoothing=1e-04), MultinomialNB(alpha=1, class_prior=None, fit_prior=True),\n",
    "               RandomForestClassifier(max_depth=6, criterion = 'gini', max_features = 'log2', n_estimators=20),AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "          learning_rate=1.8, n_estimators=50, random_state=None), GradientBoostingClassifier(),\n",
    "               KNeighborsClassifier(5), SVC(kernel=\"rbf\", C=0.25, probability=True), DecisionTreeClassifier(),\n",
    "              LinearDiscriminantAnalysis(),QuadraticDiscriminantAnalysis(tol=0.1e-6, reg_param=0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=0.0001)\n",
      "[[885 476]\n",
      " [ 32  63]]\n",
      "Accuracy: 0.6510989010989011\n",
      "Precision: 0.11688311688311688\n",
      "Recall: 0.6631578947368421\n",
      "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)\n",
      "[[1103  258]\n",
      " [  53   42]]\n",
      "Accuracy: 0.7864010989010989\n",
      "Precision: 0.14\n",
      "Recall: 0.4421052631578947\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=6, max_features='log2', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "[[1361    0]\n",
      " [  95    0]]\n",
      "Accuracy: 0.9347527472527473\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.8, n_estimators=50, random_state=None)\n",
      "[[1341   20]\n",
      " [  87    8]]\n",
      "Accuracy: 0.926510989010989\n",
      "Precision: 0.2857142857142857\n",
      "Recall: 0.08421052631578947\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "[[1351   10]\n",
      " [  94    1]]\n",
      "Accuracy: 0.9285714285714286\n",
      "Precision: 0.09090909090909091\n",
      "Recall: 0.010526315789473684\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "[[1354    7]\n",
      " [  95    0]]\n",
      "Accuracy: 0.929945054945055\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.25, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "[[1361    0]\n",
      " [  95    0]]\n",
      "Accuracy: 0.9347527472527473\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "[[1279   82]\n",
      " [  82   13]]\n",
      "Accuracy: 0.8873626373626373\n",
      "Precision: 0.1368421052631579\n",
      "Recall: 0.1368421052631579\n",
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "              solver='svd', store_covariance=False, tol=0.0001)\n",
      "[[1349   12]\n",
      " [  91    4]]\n",
      "Accuracy: 0.9292582417582418\n",
      "Precision: 0.25\n",
      "Recall: 0.042105263157894736\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.1,\n",
      "               store_covariance=False, store_covariances=None, tol=1e-07)\n",
      "[[1197  164]\n",
      " [  67   28]]\n",
      "Accuracy: 0.8413461538461539\n",
      "Precision: 0.14583333333333334\n",
      "Recall: 0.29473684210526313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\sabin\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "for model in classifiers:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print(model)\n",
    "    print(cm)\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "    print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyper parameters for all the above models were tuned manually. Among the models we trained, Logistic regression, GaussianNB and MultinomialNB (neural network models) performed well. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
